{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6488b6b",
   "metadata": {},
   "source": [
    "# Getting Started with Labellerr SDK\n",
    "\n",
    "This notebook demonstrates how to use the Labellerr SDK for video processing and scene detection. The SDK provides powerful tools for managing video datasets, processing videos, and detecting scene changes using various algorithms.\n",
    "\n",
    "### Import the required Classes from Labellerr SDK\n",
    "We'll start by importing the essential classes needed for working with the SDK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edcdab6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from labellerr.client import LabellerrClient\n",
    "from labellerr.core.datasets import LabellerrDataset\n",
    "from labellerr.core.exceptions import LabellerrError\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b7917a",
   "metadata": {},
   "source": [
    "## 1. Authentication Setup\n",
    "\n",
    "Before using the Labellerr SDK, you need to set up your authentication credentials. These credentials ensure secure access to the Labellerr platform and its services.\n",
    "\n",
    "### Required Credentials:\n",
    "\n",
    "1. **API Key & API Secret**\n",
    "   - Log in to your Labellerr account\n",
    "   - Navigate to the \"Get API\" tab\n",
    "   - Copy your unique API key and secret\n",
    "\n",
    "2. **Client ID**\n",
    "   - This is a unique identifier for your application\n",
    "   - Contact Labellerr support to obtain your client ID\n",
    "   \n",
    "⚠️ Important: Never share these credentials or commit them to version control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab12f168",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import dotenv_values\n",
    "config = dotenv_values(\".env\")\n",
    "\n",
    "api_key = config[\"API_KEY\"]\n",
    "api_secret = config[\"API_SECRET\"]\n",
    "client_id = config[\"CLIENT_ID\"]\n",
    "email = config[\"EMAIL\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2646549",
   "metadata": {},
   "source": [
    "## Kaggle Dataset Download and Project creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d2a744",
   "metadata": {},
   "source": [
    "Before downloading the dataset from Kaggle, you need to:\n",
    "\n",
    "1. Install kagglehub package using pip\n",
    "2. Authenticate with Kaggle\n",
    "3. Download the CCTV footage dataset\n",
    "\n",
    "The kagglehub package provides a simple interface to download datasets directly from Kaggle. Make sure you have a Kaggle account and API credentials set up before proceeding.\n",
    "\n",
    "Note: If you haven't set up Kaggle authentication before, you'll need to:\n",
    "1. Create a Kaggle account at https://www.kaggle.com\n",
    "2. Go to \"Account\" settings\n",
    "3. Scroll to API section and click \"Create New API Token\"\n",
    "4. This will download a kaggle.json file with your credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be12bf3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kagglehub in c:\\users\\yashs\\miniconda3\\lib\\site-packages (0.3.13)\n",
      "Requirement already satisfied: dotenv in c:\\users\\yashs\\miniconda3\\lib\\site-packages (0.9.9)\n",
      "Collecting ipywidgets\n",
      "  Downloading ipywidgets-8.1.7-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\yashs\\miniconda3\\lib\\site-packages (from kagglehub) (25.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\yashs\\miniconda3\\lib\\site-packages (from kagglehub) (6.0.3)\n",
      "Requirement already satisfied: requests in c:\\users\\yashs\\miniconda3\\lib\\site-packages (from kagglehub) (2.32.5)\n",
      "Requirement already satisfied: tqdm in c:\\users\\yashs\\miniconda3\\lib\\site-packages (from kagglehub) (4.67.1)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\yashs\\miniconda3\\lib\\site-packages (from dotenv) (1.1.0)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\users\\yashs\\miniconda3\\lib\\site-packages (from ipywidgets) (0.2.1)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\yashs\\miniconda3\\lib\\site-packages (from ipywidgets) (9.5.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\yashs\\miniconda3\\lib\\site-packages (from ipywidgets) (5.14.3)\n",
      "Collecting widgetsnbextension~=4.0.14 (from ipywidgets)\n",
      "  Downloading widgetsnbextension-4.0.14-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting jupyterlab_widgets~=3.0.15 (from ipywidgets)\n",
      "  Downloading jupyterlab_widgets-3.0.15-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\yashs\\miniconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.6)\n",
      "Requirement already satisfied: decorator in c:\\users\\yashs\\miniconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in c:\\users\\yashs\\miniconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\yashs\\miniconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\yashs\\miniconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\users\\yashs\\miniconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\yashs\\miniconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (2.19.1)\n",
      "Requirement already satisfied: stack_data in c:\\users\\yashs\\miniconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: typing_extensions>=4.6 in c:\\users\\yashs\\miniconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (4.15.0)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\yashs\\miniconda3\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\yashs\\miniconda3\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\yashs\\miniconda3\\lib\\site-packages (from requests->kagglehub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yashs\\miniconda3\\lib\\site-packages (from requests->kagglehub) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\yashs\\miniconda3\\lib\\site-packages (from requests->kagglehub) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yashs\\miniconda3\\lib\\site-packages (from requests->kagglehub) (2025.10.5)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\yashs\\miniconda3\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\yashs\\miniconda3\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure_eval in c:\\users\\yashs\\miniconda3\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Downloading ipywidgets-8.1.7-py3-none-any.whl (139 kB)\n",
      "Downloading jupyterlab_widgets-3.0.15-py3-none-any.whl (216 kB)\n",
      "Downloading widgetsnbextension-4.0.14-py3-none-any.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ------------------- -------------------- 1.0/2.2 MB 4.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.8/2.2 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 3.9 MB/s  0:00:00\n",
      "Installing collected packages: widgetsnbextension, jupyterlab_widgets, ipywidgets\n",
      "\n",
      "   -------------------------- ------------- 2/3 [ipywidgets]\n",
      "   ---------------------------------------- 3/3 [ipywidgets]\n",
      "\n",
      "Successfully installed ipywidgets-8.1.7 jupyterlab_widgets-3.0.15 widgetsnbextension-4.0.14\n"
     ]
    }
   ],
   "source": [
    "# !pip install kagglehub dotenv ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e05889d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9238b9a0f083402c926fabe84ac82a5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://www.kaggle.com/static/images/site-logo.png\\nalt=\\'Kaggle…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "kagglehub.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5b93e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\yashs\\.cache\\kagglehub\\datasets\\mistag\\short-videos\\versions\\4\n"
     ]
    }
   ],
   "source": [
    "# Download 1000 videos(~1 min) dataset\n",
    "# path_to_dataset = kagglehub.dataset_download(\"yashsuman/cctv-footage\")\n",
    "path_to_dataset = kagglehub.dataset_download(\"mistag/short-videos\")\n",
    "\n",
    "print(\"Path to dataset files:\", path_to_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d05bd0f",
   "metadata": {},
   "source": [
    "## 2. Project Configuration\n",
    "\n",
    "### Create Project with kaggle dataset\n",
    "Create a project with sample annotation template with kaggle dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e2e2f3",
   "metadata": {},
   "source": [
    "### project_payload structure (keys and purpose)\n",
    "- client_id: str — client identifier.\n",
    "- dataset_name: str — human-readable dataset name.\n",
    "- dataset_description: str — short description of the dataset.\n",
    "- data_type: str — \"video\" (or \"image\") indicating dataset type.\n",
    "- created_by: str — email of the creator/owner.\n",
    "- project_name: str — name for the new Labellerr project.\n",
    "- annotation_guide: list — annotation questions; each question includes:\n",
    "    - question_number (int), question (str), question_id (str), option_type (str),\n",
    "    - required (bool), options (list of option objects with option_name, etc.)\n",
    "- rotation_config: dict — rotation counts for annotation, review, and client review:\n",
    "    - annotation_rotation_count, review_rotation_count, client_review_rotation_count\n",
    "- autolabel: bool — whether to enable autolabeling.\n",
    "- folder_to_upload: str — local folder path containing files to upload to the project.\n",
    "\n",
    "### Typical usage steps\n",
    "1. Ensure .env has API_KEY, API_SECRET, CLIENT_ID, EMAIL and `config` is loaded.\n",
    "2. Ensure `path_to_dataset` points to the correct local dataset folder.\n",
    "3. Instantiate client if not already done:\n",
    "   client = LabellerrClient(api_key, api_secret, client_id)\n",
    "4. Review or adjust `project_payload` (annotation guide, rotation, folder_to_upload).\n",
    "5. Create the project:\n",
    "   try:\n",
    "       result = client.initiate_create_project(project_payload)\n",
    "       project_id = result['project_id']['response']['project_id']\n",
    "   except LabellerrError as e:\n",
    "       handle or log the exception\n",
    "\n",
    "## Notes & best practices\n",
    "- Do not commit API credentials to source control.\n",
    "- Verify `folder_to_upload` contains the expected video files before initiating the create-project call.\n",
    "- Customize `annotation_guide` to match your annotation schema and color/options.\n",
    "- Use rotation_config to control annotation/review distribution and workload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55b42671",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = LabellerrClient(api_key, api_secret, client_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7be23d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_dataset = r\"C:\\Users\\yashs\\.cache\\kagglehub\\datasets\\mistag\\short-videos\\versions\\4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94adb94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from labellerr.core.datasets import create_dataset\n",
    "from labellerr.core.schemas import DatasetConfig\n",
    "\n",
    "dataset = create_dataset(\n",
    "    client=client,\n",
    "    dataset_config=DatasetConfig(\n",
    "        dataset_name=\"SDK-Test\",\n",
    "        dataset_description=\"a sample dataset of video\",\n",
    "        data_type=\"video\",\n",
    "        connector_type=\"local\"\n",
    "    ),\n",
    "    folder_to_upload=path_to_dataset\n",
    ")\n",
    "\n",
    "print(f\"Dataset created with ID: {dataset.dataset_id}\")\n",
    "print(f\"Total files: {dataset.files_count}\") # only after video processing, right no is shown else 0 is shown always"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9f6eff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotation template created with ID: 1a42256a-c36a-4e9e-aea7-7b4e79ecf21a\n"
     ]
    }
   ],
   "source": [
    "from labellerr.core.projects import create_annotation_guideline\n",
    "\n",
    "questions = [\n",
    "  {\n",
    "    \"question\": \"Test_12345\",\n",
    "    \"option_type\": \"polygon\",\n",
    "    \"required\": True,\n",
    "    \"options\": [\n",
    "      { \"option_name\": \"#fe1236\" }\n",
    "    ]\n",
    "  }\n",
    "]\n",
    "\n",
    "template_id = create_annotation_guideline(\n",
    "    client=client, \n",
    "    questions=questions, \n",
    "    template_name='SDK_template', \n",
    "    data_type='video'\n",
    ")\n",
    "print(f\"Annotation template created with ID: {template_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6027577d",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_payload = {\n",
    "    'data_type': \"video\",\n",
    "    'created_by': email,\n",
    "    'project_name': \"SDK workflow\",\n",
    "    \"datasets\": [dataset.dataset_id],\n",
    "    'annotation_template_id': template_id,\n",
    "    'rotation_config': {\n",
    "        'annotation_rotation_count': 1,\n",
    "        'review_rotation_count': 1,\n",
    "        'client_review_rotation_count': 1\n",
    "    },\n",
    "    'autolabel': False,\n",
    "    # 'folder_to_upload': 'path/to/your/dataset'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2bad0ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project created successfully. Project ID: clemmie_near_guppy_37143\n"
     ]
    }
   ],
   "source": [
    "from labellerr.core.projects import create_project\n",
    "try:\n",
    "    result = create_project(client, project_payload)\n",
    "    print(f\"Project created successfully. Project ID: {result.project_id}\")\n",
    "except LabellerrError as e:\n",
    "    print(f\"Project creation failed: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1ca38e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'project_id': 'clemmie_near_guppy_37143',\n",
       " 'project_name': 'SDK workflow',\n",
       " 'created_by': 'yashsuman15@gmail.com',\n",
       " 'created_at': 1761859030067,\n",
       " 'data_type': 'video',\n",
       " 'attached_datasets': ['502ed024-2d9a-4468-8cc3-5884dfaaaa97'],\n",
       " 'annotation_template_id': '1a42256a-c36a-4e9e-aea7-7b4e79ecf21a',\n",
       " 'client_id': '14078',\n",
       " 'rotations': {'annotation_rotation_count': 1,\n",
       "  'review_rotation_count': 1,\n",
       "  'client_review_rotation_count': 1},\n",
       " 'use_ai': False,\n",
       " 'auto_label': None,\n",
       " 'origin': 'https://pro.labellerr.com',\n",
       " 'status_code': 300,\n",
       " 'indexing_job_id': '692a8948-68ea-4894-9153-a7ad1bc7a2c1',\n",
       " 'indexing_job': None,\n",
       " 'progress': {'eta': '',\n",
       "  'processed': None,\n",
       "  'start_time': None,\n",
       "  'completion_time': 1761859042261},\n",
       " 'total_files': 3}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.project_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2c7aee",
   "metadata": {},
   "source": [
    "## 3. Initializing the Labellerr SDK\n",
    "\n",
    "### Create LabellerrClient Instance\n",
    "Now we'll create instances of the main SDK classes:\n",
    "\n",
    "1. **LabellerrClient**: The main client that handles communication with the Labellerr API\n",
    "2. **LabellerrDataset**: A specialized class for working with datasets\n",
    "\n",
    "These instances will be used for all subsequent operations with the platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d91db16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'502ed024-2d9a-4468-8cc3-5884dfaaaa97'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.dataset_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9eaec7e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'labellerr.core.datasets.video_dataset.VideoDataset'>\n",
      "video\n"
     ]
    }
   ],
   "source": [
    "files = LabellerrDataset(client, dataset.dataset_id)\n",
    "print(type(dataset))\n",
    "print(dataset.data_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0aa76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "files.fetch_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900ea5a7",
   "metadata": {},
   "source": [
    "### download Videos\n",
    "The `download()` method will:\n",
    "- Fetch all videos in the dataset\n",
    "- Process them according to the configured settings\n",
    "- Return the results of the processing\n",
    "\n",
    "This is typically used as the first step in video analysis to ensure all videos are properly prepared for further processing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6db8522",
   "metadata": {},
   "source": [
    "## 4. Scene Change Detection\n",
    "\n",
    "### Available Scene Detection Methods\n",
    "Labellerr SDK provides multiple algorithms for scene detection in videos:\n",
    "\n",
    "1. **PySceneDetect**: \n",
    "   - Python-based scene detection\n",
    "   - Uses content-aware detection\n",
    "   - Good for general-purpose scene detection\n",
    "\n",
    "2. **SSIMSceneDetect**:\n",
    "   - Uses Structural Similarity Index (SSIM)\n",
    "   - Better for detecting subtle scene changes\n",
    "   - More computationally intensive but more accurate\n",
    "\n",
    "3. **FFMPEGSceneDetect**:\n",
    "   - Uses FFMPEG for scene detection\n",
    "   - Fastest method\n",
    "   - Good for quick analysis of large video files\n",
    "\n",
    "Choose the method that best suits your needs based on accuracy requirements and processing speed constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c41073",
   "metadata": {},
   "outputs": [],
   "source": [
    "from labellerr.services.video_sampling.pyscene_detect import PySceneDetect\n",
    "from labellerr.services.video_sampling.ssim import SSIMSceneDetect\n",
    "from labellerr.services.video_sampling.ffmpeg import FFMPEGSceneDetect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db88da50",
   "metadata": {},
   "source": [
    "## Scene Detection Implementation\n",
    "\n",
    "### Setting up the Scene Detector\n",
    "Now we'll set up the scene detection process:\n",
    "\n",
    "1. First, we'll define the dataset directory where our videos are stored\n",
    "2. Then we'll create an instance of our chosen detector\n",
    "3. Finally, we'll process each video in the dataset\n",
    "\n",
    "Note: Make sure you have sufficient disk space for storing the extracted scenes, as this process can generate multiple files per video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a6f89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = f\".\\Labellerr_datasets\\{dataset_id}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd96be8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = FFMPEGSceneDetect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995d99ec",
   "metadata": {},
   "source": [
    "### Initialize the Scene Detector\n",
    "Here we create an instance of the SSIMSceneDetect class. This detector uses the Structural Similarity Index Measure (SSIM) to identify scene changes in videos. SSIM is particularly effective at detecting subtle changes between frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3052f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(dataset_dir):\n",
    "    file_path = os.path.join(dataset_dir, filename)\n",
    "    \n",
    "    if os.path.isfile(file_path):\n",
    "        detector.detect_and_extract(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d64ac26",
   "metadata": {},
   "source": [
    "### Process Videos for Scene Detection\n",
    "\n",
    "The following code block:\n",
    "1. Iterates through all files in the dataset directory\n",
    "2. Constructs the full file path for each video\n",
    "3. Verifies that each path points to a file (not a directory)\n",
    "4. Applies scene detection to each video using the `detect_and_extract` method\n",
    "\n",
    "The detected scenes will be saved in a subdirectory with the same name as the input video file. Each scene will be saved as a separate video file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3eac46",
   "metadata": {},
   "source": [
    "## 5. Project Creation\n",
    "\n",
    "In this section, we'll explore how to create and manage projects in Labellerr. Projects are essential containers that organize your data and annotations. We'll cover:\n",
    "\n",
    "1. Creating image datasets from video frames\n",
    "2. Setting up annotation projects\n",
    "3. Managing project configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ba527d",
   "metadata": {},
   "source": [
    "### Image Dataset Creation from Sampled Frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b364362",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "images_files = []\n",
    "# Clear existing entries in images_files\n",
    "images_files.clear()\n",
    "\n",
    "# Construct the base directory path for detected frames\n",
    "base_dir = os.path.join(\"FFMPEG_detects\", dataset_id)\n",
    "\n",
    "# Walk through all subdirectories\n",
    "for root, dirs, files in os.walk(base_dir):\n",
    "    for file in files:\n",
    "        if file.endswith('.jpg'):  # Only collect jpg files\n",
    "            file_path = os.path.join(root, file)\n",
    "            images_files.append(file_path)\n",
    "\n",
    "print(f\"Found {len(images_files)} image files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39153ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c70986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to create dataset from sampled frames\n",
    "\n",
    "def upload_images_from_files(images_files, client, client_id):\n",
    "    \"\"\"Upload specific image files to create a dataset\"\"\"\n",
    "    \n",
    "    client.enable_connection_pooling = True\n",
    "    \n",
    "    dataset_config = {\n",
    "        \"client_id\": client_id,\n",
    "        \"dataset_name\": \"video_sampling_1\",\n",
    "        \"dataset_description\": \"video sampling dataset from frames\",\n",
    "        \"data_type\": \"image\",  \n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = client.create_dataset(\n",
    "            dataset_config=dataset_config,\n",
    "            files_to_upload=images_files  \n",
    "        )\n",
    "        print(f\"Dataset created successfully!\")\n",
    "        print(f\"Dataset ID: {response['dataset_id']}\")\n",
    "        return response['dataset_id']\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating dataset: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d96b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_images_from_files(images_files, client, client_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958fc75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataset_id = '6a680901-fe81-49f0-9120-bb754d63a341'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b454c4f4",
   "metadata": {},
   "source": [
    "### Image Annotation Project Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32106c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify to add questions to image project\n",
    "\n",
    "questions = [\n",
    "  {\n",
    "    \"question_number\": 1,\n",
    "    \"question\": \"Test\",\n",
    "    \"question_id\": \"533bb0c8-fb2b-4394-a8e1-5042a944802f\",\n",
    "    \"option_type\": \"polygon\",\n",
    "    \"required\": True,\n",
    "    \"options\": [\n",
    "      { \"option_name\": \"#fe1236\" }\n",
    "    ],\n",
    "    \"question_metadata\": []\n",
    "  }\n",
    "            ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71d2aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creeate the annotation guideline template\n",
    "\n",
    "template_id = client.create_annotation_guideline(\n",
    "    client_id=client_id,\n",
    "    questions=questions,\n",
    "    template_name=\"video_sampling_template_1\",\n",
    "    data_type=\"image\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83565ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the image annotation project\n",
    "\n",
    "response = client.create_project(\n",
    "                project_name=\"Video_sampling_project_1\",\n",
    "                data_type=\"image\",\n",
    "                client_id= client_id,\n",
    "                dataset_id=new_dataset_id,\n",
    "                annotation_template_id=template_id,\n",
    "                rotation_config={\n",
    "                    \"annotation_rotation_count\": 1,\n",
    "                    \"review_rotation_count\": 1,\n",
    "                    \"client_review_rotation_count\": 1,\n",
    "                },\n",
    "                created_by=\"yashsuman15@gmail.com\"\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f682f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if response['response']['project_id']:\n",
    "    print(f\"Project created successfully!\")\n",
    "    print(f\"Project ID: {response['response']['project_id']}\")\n",
    "    image_project_id = response['response']['project_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8645aa60",
   "metadata": {},
   "source": [
    "## 6. Performing Annotations of Image Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6eea565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# annotations of image project on labellerr platform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0611f5",
   "metadata": {},
   "source": [
    "### Exporting the Annotation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78ad296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to export the annotations from image project\n",
    "\n",
    "export_config = {\n",
    "        \"export_name\": \"Weekly Export\",\n",
    "        \"export_description\": \"Export of all accepted annotations\",\n",
    "        \"export_format\": \"coco_json\",\n",
    "        \"statuses\": [\n",
    "            \"review\",\n",
    "            \"r_assigned\",\n",
    "            \"client_review\",\n",
    "            \"cr_assigned\",\n",
    "            \"accepted\",\n",
    "        ],\n",
    "    }\n",
    "\n",
    "\n",
    "response = client.create_local_export(\n",
    "    project_id=image_project_id,\n",
    "    client_id=client_id,\n",
    "    export_config=export_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18529760",
   "metadata": {},
   "source": [
    "## 7. Uploading annotations to Video Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deae26b8",
   "metadata": {},
   "source": [
    "### Trigger SAM2 tracking on Video annotation project\n",
    "\n",
    "Using the export, retrive the prompt to run SAM2 tracking on video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6b3ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to create video annotation project from image annotations export"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
