{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6488b6b",
   "metadata": {},
   "source": [
    "# Getting Started with Labellerr SDK\n",
    "\n",
    "This notebook demonstrates how to use the Labellerr SDK for video processing and scene detection. The SDK provides powerful tools for managing video datasets, processing videos, and detecting scene changes using various algorithms.\n",
    "\n",
    "### Import the required Classes from Labellerr SDK\n",
    "We'll start by importing the essential classes needed for working with the SDK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcdab6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from labellerr.client import LabellerrClient\n",
    "from labellerr.core.datasets import LabellerrDataset\n",
    "from labellerr.exceptions import LabellerrError\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b7917a",
   "metadata": {},
   "source": [
    "## 1. Authentication Setup\n",
    "\n",
    "Before using the Labellerr SDK, you need to set up your authentication credentials. These credentials ensure secure access to the Labellerr platform and its services.\n",
    "\n",
    "### Required Credentials:\n",
    "\n",
    "1. **API Key & API Secret**\n",
    "   - Log in to your Labellerr account\n",
    "   - Navigate to the \"Get API\" tab\n",
    "   - Copy your unique API key and secret\n",
    "\n",
    "2. **Client ID**\n",
    "   - This is a unique identifier for your application\n",
    "   - Contact Labellerr support to obtain your client ID\n",
    "   \n",
    "⚠️ Important: Never share these credentials or commit them to version control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab12f168",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import dotenv_values\n",
    "config = dotenv_values(\".env\")\n",
    "\n",
    "api_key = config[\"API_KEY\"]\n",
    "api_secret = config[\"API_SECRET\"]\n",
    "client_id = config[\"CLIENT_ID\"]\n",
    "email = config[\"EMAIL\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2646549",
   "metadata": {},
   "source": [
    "## Kaggle Dataset Download and Project creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d2a744",
   "metadata": {},
   "source": [
    "Before downloading the dataset from Kaggle, you need to:\n",
    "\n",
    "1. Install kagglehub package using pip\n",
    "2. Authenticate with Kaggle\n",
    "3. Download the CCTV footage dataset\n",
    "\n",
    "The kagglehub package provides a simple interface to download datasets directly from Kaggle. Make sure you have a Kaggle account and API credentials set up before proceeding.\n",
    "\n",
    "Note: If you haven't set up Kaggle authentication before, you'll need to:\n",
    "1. Create a Kaggle account at https://www.kaggle.com\n",
    "2. Go to \"Account\" settings\n",
    "3. Scroll to API section and click \"Create New API Token\"\n",
    "4. This will download a kaggle.json file with your credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be12bf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install kagglehub dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05889d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "kagglehub.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b93e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download 1000 videos(~1 min) dataset\n",
    "path_to_dataset = kagglehub.dataset_download(\"yashsuman/cctv-footage\")\n",
    "\n",
    "\n",
    "print(\"Path to dataset files:\", path_to_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d05bd0f",
   "metadata": {},
   "source": [
    "## 2. Project Configuration\n",
    "\n",
    "### Create Project with kaggle dataset\n",
    "Create a project with sample annotation template with kaggle dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e2e2f3",
   "metadata": {},
   "source": [
    "### project_payload structure (keys and purpose)\n",
    "- client_id: str — client identifier.\n",
    "- dataset_name: str — human-readable dataset name.\n",
    "- dataset_description: str — short description of the dataset.\n",
    "- data_type: str — \"video\" (or \"image\") indicating dataset type.\n",
    "- created_by: str — email of the creator/owner.\n",
    "- project_name: str — name for the new Labellerr project.\n",
    "- annotation_guide: list — annotation questions; each question includes:\n",
    "    - question_number (int), question (str), question_id (str), option_type (str),\n",
    "    - required (bool), options (list of option objects with option_name, etc.)\n",
    "- rotation_config: dict — rotation counts for annotation, review, and client review:\n",
    "    - annotation_rotation_count, review_rotation_count, client_review_rotation_count\n",
    "- autolabel: bool — whether to enable autolabeling.\n",
    "- folder_to_upload: str — local folder path containing files to upload to the project.\n",
    "\n",
    "### Typical usage steps\n",
    "1. Ensure .env has API_KEY, API_SECRET, CLIENT_ID, EMAIL and `config` is loaded.\n",
    "2. Ensure `path_to_dataset` points to the correct local dataset folder.\n",
    "3. Instantiate client if not already done:\n",
    "   client = LabellerrClient(api_key, api_secret, client_id)\n",
    "4. Review or adjust `project_payload` (annotation guide, rotation, folder_to_upload).\n",
    "5. Create the project:\n",
    "   try:\n",
    "       result = client.initiate_create_project(project_payload)\n",
    "       project_id = result['project_id']['response']['project_id']\n",
    "   except LabellerrError as e:\n",
    "       handle or log the exception\n",
    "\n",
    "## Notes & best practices\n",
    "- Do not commit API credentials to source control.\n",
    "- Verify `folder_to_upload` contains the expected video files before initiating the create-project call.\n",
    "- Customize `annotation_guide` to match your annotation schema and color/options.\n",
    "- Use rotation_config to control annotation/review distribution and workload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f6eff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = LabellerrClient(api_key, api_secret, client_id)\n",
    "\n",
    "project_payload = {\n",
    "        \"client_id\": client_id,\n",
    "        \"dataset_name\": \"CCTV Footage Dataset\",\n",
    "        \"dataset_description\": \"A sample dataset for video annotation\",\n",
    "        \"data_type\": \"video\",\n",
    "        \"created_by\": email,\n",
    "        \"project_name\": \"SDK workflow\",\n",
    "        \"annotation_guide\": [\n",
    "            {\n",
    "                \"question_number\": 1,  # incremental series starting from 1\n",
    "                \"question\": \"Test\",  # question name\n",
    "                \"question_id\": \"533bb0c8-fb2b-4394-a8e1-5042a944802f\",  # random uuid\n",
    "                \"option_type\": \"polygon\",\n",
    "                \"required\": True,\n",
    "                \"options\": [\n",
    "                    {\n",
    "                        \"option_name\": \"#fe1236\"\n",
    "                    },  # give the hex code of some random color\n",
    "                ],\n",
    "            }\n",
    "        ],\n",
    "        \"rotation_config\": {\n",
    "            \"annotation_rotation_count\": 1,\n",
    "            \"review_rotation_count\": 1,\n",
    "            \"client_review_rotation_count\": 1,\n",
    "        },\n",
    "        \"autolabel\": False,\n",
    "        \"folder_to_upload\": path_to_dataset,\n",
    "    }\n",
    "\n",
    "try:\n",
    "    result = client.initiate_create_project(project_payload)\n",
    "    print(\n",
    "        f\"Project ID: {result['project_id']['response']['project_id']}\"\n",
    "    )\n",
    "except LabellerrError as e:\n",
    "\n",
    "    print(f\"Project creation failed: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07dcfae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id = result['project_id']['response']['project_id']\n",
    "dataset_id = client.datasets.get_all_datasets(project_id=project_id)[0]['dataset_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2c7aee",
   "metadata": {},
   "source": [
    "## 3. Initializing the Labellerr SDK\n",
    "\n",
    "### Create LabellerrClient Instance\n",
    "Now we'll create instances of the main SDK classes:\n",
    "\n",
    "1. **LabellerrClient**: The main client that handles communication with the Labellerr API\n",
    "2. **LabellerrDataset**: A specialized class for working with datasets\n",
    "\n",
    "These instances will be used for all subsequent operations with the platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eaec7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# client = LabellerrClient(api_key, api_secret, client_id)\n",
    "dataset = LabellerrDataset(client, dataset_id, project_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6a7052",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = dataset.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900ea5a7",
   "metadata": {},
   "source": [
    "### download Videos\n",
    "The `download()` method will:\n",
    "- Fetch all videos in the dataset\n",
    "- Process them according to the configured settings\n",
    "- Return the results of the processing\n",
    "\n",
    "This is typically used as the first step in video analysis to ensure all videos are properly prepared for further processing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6db8522",
   "metadata": {},
   "source": [
    "## 4. Scene Change Detection\n",
    "\n",
    "### Available Scene Detection Methods\n",
    "Labellerr SDK provides multiple algorithms for scene detection in videos:\n",
    "\n",
    "1. **PySceneDetect**: \n",
    "   - Python-based scene detection\n",
    "   - Uses content-aware detection\n",
    "   - Good for general-purpose scene detection\n",
    "\n",
    "2. **SSIMSceneDetect**:\n",
    "   - Uses Structural Similarity Index (SSIM)\n",
    "   - Better for detecting subtle scene changes\n",
    "   - More computationally intensive but more accurate\n",
    "\n",
    "3. **FFMPEGSceneDetect**:\n",
    "   - Uses FFMPEG for scene detection\n",
    "   - Fastest method\n",
    "   - Good for quick analysis of large video files\n",
    "\n",
    "Choose the method that best suits your needs based on accuracy requirements and processing speed constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c41073",
   "metadata": {},
   "outputs": [],
   "source": [
    "from labellerr.services.video_sampling.pyscene_detect import PySceneDetect\n",
    "from labellerr.services.video_sampling.ssim import SSIMSceneDetect\n",
    "from labellerr.services.video_sampling.ffmpeg import FFMPEGSceneDetect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db88da50",
   "metadata": {},
   "source": [
    "## Scene Detection Implementation\n",
    "\n",
    "### Setting up the Scene Detector\n",
    "Now we'll set up the scene detection process:\n",
    "\n",
    "1. First, we'll define the dataset directory where our videos are stored\n",
    "2. Then we'll create an instance of our chosen detector\n",
    "3. Finally, we'll process each video in the dataset\n",
    "\n",
    "Note: Make sure you have sufficient disk space for storing the extracted scenes, as this process can generate multiple files per video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a6f89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = f\".\\Labellerr_datasets\\{dataset_id}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd96be8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = FFMPEGSceneDetect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995d99ec",
   "metadata": {},
   "source": [
    "### Initialize the Scene Detector\n",
    "Here we create an instance of the SSIMSceneDetect class. This detector uses the Structural Similarity Index Measure (SSIM) to identify scene changes in videos. SSIM is particularly effective at detecting subtle changes between frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3052f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(dataset_dir):\n",
    "    file_path = os.path.join(dataset_dir, filename)\n",
    "    \n",
    "    if os.path.isfile(file_path):\n",
    "        detector.detect_and_extract(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d64ac26",
   "metadata": {},
   "source": [
    "### Process Videos for Scene Detection\n",
    "\n",
    "The following code block:\n",
    "1. Iterates through all files in the dataset directory\n",
    "2. Constructs the full file path for each video\n",
    "3. Verifies that each path points to a file (not a directory)\n",
    "4. Applies scene detection to each video using the `detect_and_extract` method\n",
    "\n",
    "The detected scenes will be saved in a subdirectory with the same name as the input video file. Each scene will be saved as a separate video file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3eac46",
   "metadata": {},
   "source": [
    "## 5. Project Creation\n",
    "\n",
    "In this section, we'll explore how to create and manage projects in Labellerr. Projects are essential containers that organize your data and annotations. We'll cover:\n",
    "\n",
    "1. Creating image datasets from video frames\n",
    "2. Setting up annotation projects\n",
    "3. Managing project configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ba527d",
   "metadata": {},
   "source": [
    "### Image Dataset Creation from Sampled Frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b364362",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "images_files = []\n",
    "# Clear existing entries in images_files\n",
    "images_files.clear()\n",
    "\n",
    "# Construct the base directory path for detected frames\n",
    "base_dir = os.path.join(\"FFMPEG_detects\", dataset_id)\n",
    "\n",
    "# Walk through all subdirectories\n",
    "for root, dirs, files in os.walk(base_dir):\n",
    "    for file in files:\n",
    "        if file.endswith('.jpg'):  # Only collect jpg files\n",
    "            file_path = os.path.join(root, file)\n",
    "            images_files.append(file_path)\n",
    "\n",
    "print(f\"Found {len(images_files)} image files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39153ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c70986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to create dataset from sampled frames\n",
    "\n",
    "def upload_images_from_files(images_files, client, client_id):\n",
    "    \"\"\"Upload specific image files to create a dataset\"\"\"\n",
    "    \n",
    "    client.enable_connection_pooling = True\n",
    "    \n",
    "    dataset_config = {\n",
    "        \"client_id\": client_id,\n",
    "        \"dataset_name\": \"video_sampling_1\",\n",
    "        \"dataset_description\": \"video sampling dataset from frames\",\n",
    "        \"data_type\": \"image\",  \n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = client.create_dataset(\n",
    "            dataset_config=dataset_config,\n",
    "            files_to_upload=images_files  \n",
    "        )\n",
    "        print(f\"Dataset created successfully!\")\n",
    "        print(f\"Dataset ID: {response['dataset_id']}\")\n",
    "        return response['dataset_id']\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating dataset: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d96b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_images_from_files(images_files, client, client_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958fc75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataset_id = '6a680901-fe81-49f0-9120-bb754d63a341'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b454c4f4",
   "metadata": {},
   "source": [
    "### Image Annotation Project Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32106c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify to add questions to image project\n",
    "\n",
    "questions = [\n",
    "  {\n",
    "    \"question_number\": 1,\n",
    "    \"question\": \"Test\",\n",
    "    \"question_id\": \"533bb0c8-fb2b-4394-a8e1-5042a944802f\",\n",
    "    \"option_type\": \"polygon\",\n",
    "    \"required\": True,\n",
    "    \"options\": [\n",
    "      { \"option_name\": \"#fe1236\" }\n",
    "    ],\n",
    "    \"question_metadata\": []\n",
    "  }\n",
    "            ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71d2aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creeate the annotation guideline template\n",
    "\n",
    "template_id = client.create_annotation_guideline(\n",
    "    client_id=client_id,\n",
    "    questions=questions,\n",
    "    template_name=\"video_sampling_template_1\",\n",
    "    data_type=\"image\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83565ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the image annotation project\n",
    "\n",
    "response = client.create_project(\n",
    "                project_name=\"Video_sampling_project_1\",\n",
    "                data_type=\"image\",\n",
    "                client_id= client_id,\n",
    "                dataset_id=new_dataset_id,\n",
    "                annotation_template_id=template_id,\n",
    "                rotation_config={\n",
    "                    \"annotation_rotation_count\": 1,\n",
    "                    \"review_rotation_count\": 1,\n",
    "                    \"client_review_rotation_count\": 1,\n",
    "                },\n",
    "                created_by=\"yashsuman15@gmail.com\"\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f682f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if response['response']['project_id']:\n",
    "    print(f\"Project created successfully!\")\n",
    "    print(f\"Project ID: {response['response']['project_id']}\")\n",
    "    image_project_id = response['response']['project_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8645aa60",
   "metadata": {},
   "source": [
    "## 6. Performing Annotations of Image Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6eea565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# annotations of image project on labellerr platform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0611f5",
   "metadata": {},
   "source": [
    "### Exporting the Annotation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78ad296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to export the annotations from image project\n",
    "\n",
    "export_config = {\n",
    "        \"export_name\": \"Weekly Export\",\n",
    "        \"export_description\": \"Export of all accepted annotations\",\n",
    "        \"export_format\": \"coco_json\",\n",
    "        \"statuses\": [\n",
    "            \"review\",\n",
    "            \"r_assigned\",\n",
    "            \"client_review\",\n",
    "            \"cr_assigned\",\n",
    "            \"accepted\",\n",
    "        ],\n",
    "    }\n",
    "\n",
    "\n",
    "response = client.create_local_export(\n",
    "    project_id=image_project_id,\n",
    "    client_id=client_id,\n",
    "    export_config=export_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18529760",
   "metadata": {},
   "source": [
    "## 7. Uploading annotations to Video Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deae26b8",
   "metadata": {},
   "source": [
    "### Trigger SAM2 tracking on Video annotation project\n",
    "\n",
    "Using the export, retrive the prompt to run SAM2 tracking on video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6b3ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to create video annotation project from image annotations export"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SDK",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
